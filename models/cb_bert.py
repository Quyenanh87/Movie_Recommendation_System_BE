import torch
import pandas as pd
import numpy as np
from utils.dataset import get_user_history
from transformers import AutoTokenizer, AutoModel

print("[DEBUG] ƒêang load BERT model...")
# Load model v√† tokenizer
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_name = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
bert_model = AutoModel.from_pretrained(model_name)
bert_model.eval()
bert_model.to(device)

print("[DEBUG] ƒêang load d·ªØ li·ªáu t·ª´ file pkl...")
# Load model data
model_data = torch.load('file_pkl/bert_recommender_full.pt', map_location=device)

print("[DEBUG] C√°c th√†nh ph·∫ßn trong model:", list(model_data.keys()))

# Extract c√°c th√†nh ph·∫ßn
embedding_cache = model_data['embedding_cache']
movieId_to_content = model_data['movieId_to_content'] 
movies = model_data['movies_df']
user_train_rating = model_data['user_train_rating']

def get_bert_embedding(text):
    """L·∫•y embedding t·ª´ cache ho·∫∑c t√≠nh m·ªõi n·∫øu ch∆∞a c√≥"""
    if text in embedding_cache:
        return embedding_cache[text]
    
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(device)
    with torch.no_grad():
        outputs = bert_model(**inputs)
    emb = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()
    embedding_cache[text] = emb
    return emb

def build_user_profile(user_movies):
    """X√¢y d·ª±ng profile ng∆∞·ªùi d√πng t·ª´ danh s√°ch phim ƒë√£ xem"""
    if not user_movies:
        return None
        
    # L·∫•y content v√† embedding cho t·ª´ng phim
    embeddings = []
    for movie in user_movies:
        if movie in movieId_to_content:
            content = movieId_to_content[movie]
            emb = get_bert_embedding(content)
            embeddings.append(emb)
    
    if not embeddings:
        return None
        
    # T√≠nh trung b√¨nh c√°c embedding
    return np.mean(embeddings, axis=0)

def compute_similarity(embedding1, embedding2):
    """T√≠nh cosine similarity gi·ªØa 2 embedding"""
    return np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))

def recommend_topk_for_user(user_id, top_k=10):
    """
    H√†m g·ª£i √Ω top-k phim cho m·ªôt user s·ª≠ d·ª•ng BERT embeddings
    """
    if user_id not in user_train_rating:
        print(f"‚ùå User {user_id} kh√¥ng c√≥ trong d·ªØ li·ªáu hu·∫•n luy·ªán.")
        return {
            "success": False,
            "message": f"User {user_id} kh√¥ng c√≥ trong d·ªØ li·ªáu hu·∫•n luy·ªán.",
            "recommendations": []
        }

    # L·∫•y danh s√°ch phim ƒë√£ xem
    train_movies = user_train_rating[user_id]
    
    # X√¢y d·ª±ng user profile
    user_profile = build_user_profile(train_movies)
    if user_profile is None:
        print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x√¢y d·ª±ng h·ªì s∆° ng∆∞·ªùi d√πng cho user {user_id}.")
        return {
            "success": False,
            "message": "Kh√¥ng th·ªÉ x√¢y d·ª±ng h·ªì s∆° ng∆∞·ªùi d√πng.",
            "recommendations": []
        }

    # L·∫•y danh s√°ch phim ch∆∞a xem
    train_set = set(train_movies)
    candidate_ids = list(set(movieId_to_content.keys()) - train_set)

    # T√≠nh similarity v·ªõi t·∫•t c·∫£ phim ch∆∞a xem
    similarities = []
    for mid in candidate_ids:
        content = movieId_to_content[mid]
        movie_emb = get_bert_embedding(content)
        sim = compute_similarity(user_profile, movie_emb)
        similarities.append((mid, sim))

    # S·∫Øp x·∫øp v√† l·∫•y top-k phim
    top_items = sorted(similarities, key=lambda x: -x[1])[:top_k]
    
    print(f"\nüéØ Top-{top_k} phim g·ª£i √Ω cho user {user_id}:")
    
    recommendations = []
    for mid, sim in top_items:
        title = movies.loc[movies['movieId'] == mid, 'title'].values[0]
        print(f"{title} (similarity: {sim:.4f})")
        recommendations.append({
            "title": title,
            "similarity": float(sim),
            "movieId": int(mid)
        })

    return {
        "success": True,
        "message": f"ƒê√£ t√¨m th·∫•y {len(recommendations)} g·ª£i √Ω ph√π h·ª£p",
        "recommendations": recommendations
    }

def recommend(user_id=None, liked_movies=None, top_n=5):
    """
    H√†m recommend ch√≠nh ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi API
    """
    # ∆Øu ti√™n d√πng l·ªãch s·ª≠ n·∫øu kh√¥ng truy·ªÅn liked_movies
    if not liked_movies and user_id:
        liked_movies = get_user_history(user_id)
        print("[DEBUG] L·ªãch s·ª≠ phim ƒë√£ xem:", liked_movies)

    if not liked_movies:
        print("[DEBUG] Kh√¥ng t√¨m th·∫•y l·ªãch s·ª≠ xem phim")
        return ["Kh√¥ng t√¨m th·∫•y phim ph√π h·ª£p"]

    # N·∫øu c√≥ user_id, d√πng BERT ƒë·ªÉ g·ª£i √Ω
    if user_id:
        print(f"\n[DEBUG] ƒêang t√¨m g·ª£i √Ω cho user {user_id}...")
        result = recommend_topk_for_user(user_id, top_k=top_n)
        if result["success"]:
            recommendations = [rec["title"] for rec in result["recommendations"]]
            print(f"[DEBUG] Danh s√°ch phim g·ª£i √Ω: {recommendations}")
            return recommendations
        print("[DEBUG] Kh√¥ng t√¨m ƒë∆∞·ª£c g·ª£i √Ω ph√π h·ª£p")
        return ["Kh√¥ng t√¨m th·∫•y phim ph√π h·ª£p"]

    # N·∫øu kh√¥ng c√≥ user_id nh∆∞ng c√≥ liked_movies, tr·∫£ v·ªÅ top_n phim t·ª´ danh s√°ch
    print("\n[DEBUG] ƒêang x·ª≠ l√Ω danh s√°ch phim y√™u th√≠ch...")
    pool = [title for title in liked_movies if isinstance(title, str)]
    pool = list(set(pool))  # lo·∫°i tr√πng
    print(f"[DEBUG] Danh s√°ch phim h·ª£p l·ªá: {pool}")
    
    if not pool:
        print("[DEBUG] Kh√¥ng c√≥ phim h·ª£p l·ªá trong danh s√°ch")
        return ["Kh√¥ng t√¨m th·∫•y phim ph√π h·ª£p"]
    
    result = pool[:top_n]
    print(f"[DEBUG] K·∫øt qu·∫£ g·ª£i √Ω cu·ªëi c√πng: {result}")
    return result